{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Required Imports\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection  import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Data Points:  2225\n",
      "News Categories/Labels:  Counter({'sport': 511, 'business': 510, 'politics': 417, 'tech': 401, 'entertainment': 386})\n"
     ]
    }
   ],
   "source": [
    "#Code To Combine Multiple Files Into A Single File.\n",
    "features = []\n",
    "labels = []\n",
    "direc = 'bbc/'\n",
    "folders = os.listdir(direc)\n",
    "translator = str.maketrans('','', string.punctuation)\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def parseOutText(all_text):\n",
    "    '''\n",
    "       Function To Remove Punctuations, Alpha-Numeric Words \n",
    "       And To Stem Those Words. \n",
    "    '''\n",
    "    all_text = all_text.translate(translator).replace('\\n', ' ')\n",
    "    words_lst = all_text.split(' ')\n",
    "    complete_sentence = ''\n",
    "    for word in words_lst:\n",
    "        word = stemmer.stem(word.strip())\n",
    "        if word != '' and word.isalpha():\n",
    "            complete_sentence += (word + ' ')\n",
    "\n",
    "    return complete_sentence.strip()    \n",
    "\n",
    "for folder in folders:\n",
    "    path = (direc+folder)\n",
    "    files = (os.listdir(path))\n",
    "    for file in files:\n",
    "        f = open(path+'/'+file)\n",
    "        features.append(parseOutText(f.read()))\n",
    "        labels.append(folder)\n",
    "                \n",
    "print('Total Number Of Data Points: ',len(features))\n",
    "print('News Categories/Labels: ', Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Data Points In Training Set:  1780\n",
      "Number Of Data Points In Testing Set:  445\n"
     ]
    }
   ],
   "source": [
    "#Splitting The Features And Labels Into Training And Testing Sets.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, \n",
    "                                            test_size = 0.2, random_state = 100)\n",
    "\n",
    "print('Number Of Data Points In Training Set: ',len(features_train))\n",
    "print('Number Of Data Points In Testing Set: ',len(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19060"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implementing TfidfVectorizer To Extract Features From Text.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "train_tfidf = vectorizer.fit_transform(features_train)\n",
    "array = train_tfidf.toarray()\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#Lets Print The First Row Of Vectorized Array\n",
    "print(array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['afterward', 'ahead', 'announc', 'asian', 'atp', 'beat', 'becam',\n",
      "       'befor', 'bounc', 'carlo', 'chennai', 'claim', 'close', 'confirm',\n",
      "       'contribut', 'decemb', 'decid', 'defend', 'differ', 'disast',\n",
      "       'donat', 'effort', 'emerg', 'far', 'fee', 'fight', 'final',\n",
      "       'finalist', 'follow', 'forc', 'fourtim', 'fund', 'hope', 'im',\n",
      "       'increas', 'indian', 'kill', 'live', 'make', 'man', 'merced',\n",
      "       'money', 'moya', 'nadu', 'open', 'paradorn', 'peopl', 'player',\n",
      "       'pledg', 'prize', 'relief', 'said', 'scrichapan', 'second', 'seed',\n",
      "       'set', 'spaniard', 'sponsor', 'srichaphan', 'success', 'tamil',\n",
      "       'thai', 'thailand', 'tiebreak', 'titl', 'took', 'tour',\n",
      "       'tournament', 'tsunami', 'unicef', 'unspecifi', 'victim', 'went',\n",
      "       'win', 'winner', 'work'], \n",
      "      dtype='<U31')]\n"
     ]
    }
   ],
   "source": [
    "#The Vectorized Array Can Be Converted To Words Using The Inverse Function\n",
    "print(vectorizer.inverse_transform(array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Fit The Vectorized Data And Respective Labels To MultinomialNB\n",
    "textClassifier = MultinomialNB()\n",
    "textClassifier.fit(train_tfidf, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy:  0.973033707865\n"
     ]
    }
   ],
   "source": [
    "#Lets Transform The Test Data To perform Predictions.\n",
    "test_tfidf = vectorizer.transform(features_test)\n",
    "pred = textClassifier.predict(test_tfidf)\n",
    "print('The Accuracy: ',accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy:  0.98202247191\n"
     ]
    }
   ],
   "source": [
    "#The Above Performed Steps For Vectorizing The Data And Then Fitting It To A Classifier Can Be Reduced As Follows.\n",
    "#For This Model Lets Use A CountVectorizer\n",
    "model = make_pipeline(CountVectorizer(stop_words='english'),MultinomialNB())\n",
    "model.fit(features_train, labels_train)\n",
    "pred = model.predict(features_test)\n",
    "print('The Accuracy: ',accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now Lets Write A Fn That Can Be Used For Our Own Sample Examples.\n",
    "def predict(s, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entertainment'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Titanic is a classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('cricket is a very famous sport in India')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
