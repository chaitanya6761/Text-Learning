{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moview Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Required Imports\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from random import shuffle\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Data Points In Reviews:  2000\n"
     ]
    }
   ],
   "source": [
    "root = 'Data/'\n",
    "folders = os.listdir(root)\n",
    "movie_reviews = []\n",
    "translator = str.maketrans('','', string.punctuation)\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def parseOutText(all_text):\n",
    "    '''\n",
    "       Function To Remove Punctuations, Alpha-Numeric Words \n",
    "       And To Stem Those Words. \n",
    "    '''\n",
    "    all_text = all_text.translate(translator).replace('\\n', ' ')\n",
    "    words_lst = all_text.split(' ')\n",
    "    complete_sentence = ''\n",
    "    for word in words_lst:\n",
    "        word = stemmer.stem(word.strip())\n",
    "        if word != '' and word.isalpha() and word not in stop_words:\n",
    "            complete_sentence += (word + ' ')\n",
    "\n",
    "    return complete_sentence.strip()\n",
    "\n",
    "\n",
    "# This Code Is To Read Data From Different Folders And Combine Them Into A Single Array\n",
    "for folder in folders:\n",
    "    path = (root + folder +'/')\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        f = open(path + file)\n",
    "        if folder == 'neg':\n",
    "            movie_reviews.append([parseOutText(f.read()),-1])\n",
    "        elif folder == 'pos':\n",
    "            movie_reviews.append([parseOutText(f.read()),1])     \n",
    "            \n",
    "print('Total Number Data Points In Reviews: ',len(movie_reviews))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Data Points In Training Set:  1800\n",
      "Total Number Of Data Points In Testing Set:  200\n"
     ]
    }
   ],
   "source": [
    "#Lets Seperate The Data Into Training And Testing Sets.\n",
    "shuffle(movie_reviews)\n",
    "\n",
    "train_data = movie_reviews[:1800]\n",
    "test_data = movie_reviews[1800:]\n",
    "\n",
    "print('Total Number Of Data Points In Training Set: ',len(train_data))\n",
    "print('Total Number Of Data Points In Testing Set: ',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive text sample:  devil take ask rhetor lull voic spoil titl charact onegin pronounc ohneggin wait death reliev lifetim rapaci behaviour martha fienn debut featur quit liter film poetri base epic russian poem alexand pushkin profound studi regret confus shame guilt first meet eugen onegin ralph act sister anoth brother magnus compos sco\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Negative text sample:  yet anoth brainless teen flick one surpris drug sex star kati holm sarah polli couldnt look bore charact cardboard cutout everi clich teenag one thing need know realli hate movi everyth annoy hell act script plot end director fluke hit swinger could veri well direct bunch nonam actor watchab film big star go pretti muc\n"
     ]
    }
   ],
   "source": [
    "def get_text(reviews, score):\n",
    "    '''\n",
    "        This function is to collect data for a particular tone\n",
    "    '''\n",
    "    return \"\".join([r[0].lower() for r in reviews if r[1] == (score)])\n",
    "\n",
    "def count_text(text):\n",
    "    '''\n",
    "        This function is to collect features from a particular tone.\n",
    "    '''\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    return Counter(words)\n",
    "    \n",
    "positive_text = get_text(train_data, 1)\n",
    "negative_text = get_text(train_data, -1)\n",
    "\n",
    "positive_counts = count_text(positive_text)\n",
    "negative_counts = count_text(negative_text)\n",
    "    \n",
    "print('Positive text sample: ', positive_text[:320])\n",
    "print('------------------------------------------------------------------------------------------------------------')\n",
    "print('Negative text sample: ', negative_text[:320]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Of Positive Reviews In Training Set:  905\n",
      "Total Number Of Negative Reviews In Training Set:  895\n",
      "------------------------------------------------------------------\n",
      "Prior Probability Of Being Positive Review:  0.5027777777777778\n",
      "Prior Probability Of Being Negative Review:  0.49722222222222223\n"
     ]
    }
   ],
   "source": [
    "def get_y_count(score):\n",
    "    '''\n",
    "        This function is to return the total number of reviews of a particular tone \n",
    "    '''\n",
    "    return len([r for r in train_data if r[1] == score])\n",
    "\n",
    "positive_review_count = get_y_count(1)\n",
    "negative_review_count = get_y_count(-1)\n",
    "\n",
    "\n",
    "#Prior probabilities\n",
    "prob_positive = positive_review_count/len(train_data)\n",
    "prob_negative = negative_review_count/len(train_data)\n",
    "\n",
    "print('Total Number Of Positive Reviews In Training Set: ',positive_review_count)\n",
    "print('Total Number Of Negative Reviews In Training Set: ',negative_review_count)\n",
    "print('------------------------------------------------------------------')\n",
    "print('Prior Probability Of Being Positive Review: ',prob_positive)\n",
    "print('Prior Probability Of Being Negative Review: ',prob_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yet anoth brainless teen flick one surpris drug sex star kati holm sarah polli couldnt look bore charact cardboard cutout everi clich teenag one thing need know realli hate movi everyth annoy hell act script plot end director fluke hit swinger could veri well direct bunch nonam actor watchab film big star go pretti much drown project ani origin felt like watch dawson creek episod although film still would stay red despit cast surpris end sooo predict sinc male charact sudden outing closet consid surpris hollywood anymor go dawson creek varsiti blue shes go home watch someth els\n",
      "\n",
      "Negative prediction: 9.30633075462063e-283\n",
      "Positive prediction: 3.0618995093496967e-291\n"
     ]
    }
   ],
   "source": [
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "    \n",
    "    prediction = 1\n",
    "    text_counts = Counter(re.split(\"\\s+\", text))\n",
    "    \n",
    "    for word in text_counts:\n",
    "        prediction *= text_counts.get(word) * ((counts.get(word,0)+1) / (sum(counts.values()) + class_count))\n",
    "    return class_prob * prediction\n",
    "print(train_data[0][0])\n",
    "print(\"\\nNegative prediction: {0}\".format(make_class_prediction(train_data[0][0], negative_counts, prob_negative, negative_review_count)))\n",
    "print(\"Positive prediction: {0}\".format(make_class_prediction(train_data[0][0], positive_counts, prob_positive, positive_review_count)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.54\n"
     ]
    }
   ],
   "source": [
    "def make_decision(text, make_class_prediction):\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_review_count)    \n",
    "    \n",
    "    if negative_prediction < positive_prediction:\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "def calculate_Accuracy(predictions):\n",
    "    actual_labels = [r[1] for r in test_data]\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if actual_labels[i] == (predictions[i]):\n",
    "            count += 1\n",
    "        \n",
    "    print('Accuracy: ',count/len(actual_labels))\n",
    "    \n",
    "    \n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test_data]\n",
    "calculate_Accuracy(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "train_features  = vectorizer.fit_transform([r[0] for r in train_data])\n",
    "test_features = vectorizer.transform([r[0] for r in test_data])\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, [int(r[1]) for r in train_data])\n",
    "\n",
    "predictions = classifier.predict(test_features)\n",
    "calculate_Accuracy(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
