{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bayes Theorem Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of being tired, given that you ran:  0.6\n"
     ]
    }
   ],
   "source": [
    "days = [[\"ran\", \"was tired\"], [\"ran\", \"was not tired\"], \n",
    "        [\"didn't run\", \"was tired\"], [\"ran\", \"was tired\"], \n",
    "        [\"didn't run\", \"was not tired\"], [\"ran\", \"was not tired\"], [\"ran\", \"was tired\"]]\n",
    "\n",
    "#lets say that we want to calculate the odds that someone was tired, given that they ran using naive bayes.\n",
    "#This is P(A)\n",
    "prob_tired = len([d for d in days if d[1] == 'was tired'])/len(days)\n",
    "\n",
    "#This is P(B)\n",
    "prob_ran = len([d for d in days if d[0] == 'ran'])/len(days)\n",
    "\n",
    "#This is P(B|A)\n",
    "prob_ran_given_tired = len([d for d in days if d[0] == \"ran\" and d[1] == \"was tired\"]) / len([d for d in days if d[1] == \"was tired\"])  \n",
    "\n",
    "#Now we can calculate P(A|B)\n",
    "\n",
    "prob_tired_given_ran = (prob_ran_given_tired * prob_tired) / prob_ran\n",
    "\n",
    "print('The probability of being tired, given that you ran: ',prob_tired_given_ran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tired Probability:  0.10204081632653061\n",
      "Not Tired Probability:  0.054421768707482984\n",
      "Classificaton:  was tired\n"
     ]
    }
   ],
   "source": [
    "# Here's our data, but with \"woke up early\" or \"didn't wake up early\" added.\n",
    "days = [[\"ran\", \"was tired\", \"woke up early\"], [\"ran\", \"was not tired\", \"didn't wake up early\"], \n",
    "        [\"didn't run\", \"was tired\", \"woke up early\"], [\"ran\", \"was tired\", \"didn't wake up early\"], \n",
    "        [\"didn't run\", \"was tired\", \"woke up early\"], [\"ran\", \"was not tired\", \"didn't wake up early\"], \n",
    "        [\"ran\", \"was tired\", \"woke up early\"]]\n",
    "\n",
    "# We're trying to predict whether or not the person was tired on this day.\n",
    "new_day = [\"ran\", \"didn't wake up early\"]\n",
    "\n",
    "def calc_y_prob(y_label, days):\n",
    "    return len([d for d in days if d[1] == y_label])/len(days)\n",
    "\n",
    "def calc_ran_prob_given_y(ran_label, y_label, days):\n",
    "    return len([d for d in days if d[0] == ran_label and d[1] == y_label])/len(days)\n",
    "\n",
    "def calc_woke_early_prob_given_y(woke_label, y_label, days):\n",
    "    return len([d for d in days if d[2] == woke_label and d[1] == y_label])/len(days)\n",
    "\n",
    "denominator = len([d for d in days if d[0] == new_day[0] and d[2] == new_day[1]])/len(days)\n",
    "\n",
    "\n",
    "#Lets plugin all the values and find out the label for given data point.\n",
    "prob_tired = calc_y_prob('was tired', days) * calc_ran_prob_given_y(new_day[0], 'was tired', days) * calc_woke_early_prob_given_y(new_day[1], 'was tired', days) / denominator \n",
    "\n",
    "prob_not_tired = calc_y_prob('was not tired', days) * calc_ran_prob_given_y(new_day[0], 'was not tired', days) * calc_woke_early_prob_given_y(new_day[1], 'was not tired', days) / denominator \n",
    "\n",
    "\n",
    "#Now lets make a classifiaction deceision based on probabilities\n",
    "\n",
    "print('Tired Probability: ',prob_tired)\n",
    "print('Not Tired Probability: ',prob_not_tired)\n",
    "\n",
    "classifiaction = 'was tired'\n",
    "if prob_tired < prob_not_tired:\n",
    "    classifiaction = 'was not tired'\n",
    "    \n",
    "print('Classificaton: ',classifiaction)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Text Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Positive Text Sample:  bromwell high is a cartoon comedy. it ran at the same time as some other programs about school life,\n",
      "Negative Text Sample:  story of a man who has unnatural feelings for a pig. starts out with a opening scene that is a terri\n",
      "-----------------------------------------------\n",
      "Features In Positive Text:  29094\n",
      "Features In Negative Text:  29254\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "import re\n",
    "\n",
    "#Read In The Training Data\n",
    "with open('train.csv', 'r',encoding=\"utf8\") as file:\n",
    "    reviews = list(csv.reader(file))\n",
    "    \n",
    "def get_text(reviews, score):\n",
    "    return ' '.join([r[0].lower() for r in reviews if r[1] == str(score)])\n",
    "    \n",
    "def count_text(text):\n",
    "    words = re.split('\\s+', text)\n",
    "    return Counter(words)\n",
    "\n",
    "    \n",
    "#positive reviews:\n",
    "positive_text = get_text(reviews, '1')\n",
    "#negative reviews:\n",
    "negative_text = get_text(reviews, '-1')\n",
    "\n",
    "#Generate Word Counts For Positive Text\n",
    "positive_counts = count_text(positive_text)\n",
    "\n",
    "#Generate Word Counts For Negative Text\n",
    "negative_counts = count_text(negative_text)\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print(\"Positive Text Sample: \",positive_text[:100])\n",
    "print(\"Negative Text Sample: \",negative_text[:100])\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print(\"Features In Positive Text: \",len(positive_counts))\n",
    "print(\"Features In Negative Text: \",len(negative_counts))\n",
    "\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Total Number Of Reviews:  2000\n",
      "Total Number Of Positive Reviews:  1000\n",
      "Total Number Of Negative Reviews:  1000\n",
      "-----------------------------------------------\n",
      "Class Probabilty Of Being Positive Text:  0.5\n",
      "Class Probabilty Of Being Negative Text:  0.5\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_y_count(score):\n",
    "    return len([r for r in reviews if r[1] == str(score)])\n",
    "\n",
    "positive_review_count = get_y_count(-1)\n",
    "negative_review_count = get_y_count(1)\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print('Total Number Of Reviews: ',len(reviews))\n",
    "print('Total Number Of Positive Reviews: ',positive_review_count)\n",
    "print('Total Number Of Negative Reviews: ',positive_review_count)    \n",
    "print('-----------------------------------------------')\n",
    "\n",
    "prob_positive = positive_review_count/len(reviews)\n",
    "prob_negative = negative_review_count/len(reviews)\n",
    "\n",
    "print('Class Probabilty Of Being Positive Text: ',prob_positive)\n",
    "print('Class Probabilty Of Being Negative Text: ',prob_negative)\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  [\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\", '-1']\n",
      "Negative prediction:  0.0\n",
      "Positive prediction:  0.0\n"
     ]
    }
   ],
   "source": [
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "    prediction = 1\n",
    "    text_counts = Counter(re.split(\"\\s+\", text))\n",
    "    #print(text_counts)\n",
    "    for word in text_counts:\n",
    "        prediction *=  float(text_counts.get(word)) * ((counts.get(word, 0) + 1) / (sum(counts.values()) + class_count))\n",
    "        #print(prediction)\n",
    "    return prediction * class_prob\n",
    "\n",
    "print(\"Review: \",reviews[0])\n",
    "print(\"Negative prediction: \",make_class_prediction(reviews[10][0], negative_counts, prob_negative, negative_review_count))\n",
    "print(\"Positive prediction: \",make_class_prediction(reviews[100][0], positive_counts, prob_positive, positive_review_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predicting The TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_decision(text, make_class_prediction):\n",
    "    neg_pred = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    pos_pred = make_class_prediction(text, positive_counts, prob_positive, negative_review_count) \n",
    "    \n",
    "    if neg_pred > pos_pred :\n",
    "        return -1\n",
    "    \n",
    "    return 1\n",
    "\n",
    "with open('test.csv', 'r', encoding=\"utf8\") as file:\n",
    "    test = list(csv.reader(file))\n",
    "    \n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.559\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "actual_labels = [r[1] for r in test]\n",
    "count = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if actual_labels[i] == str(predictions[i]):\n",
    "        count += 1\n",
    "        \n",
    "print('Accuracy: ',count/len(actual_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
